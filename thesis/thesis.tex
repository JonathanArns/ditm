\documentclass[a4paper]{report}

\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{multirow}
\usepackage{float}
\usepackage[english,ngerman]{babel}
\usepackage[backend=biber,
            sorting=none,   % Keine Sortierung
            doi=true,       % DOI anzeigen
            isbn=true,      % ISBN nicht anzeigen
            url=true,       % URLs anzeigen
            maxnames=6,     % Ab 6 Autoren et al. verwenden
            minnames=1,     % und nur den ersten Autor angeben
            style=numeric-comp,]{biblatex}
\addbibresource{literatur.bib}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\begin{document}

\title{Erzeugung, Aufzeichnung und Wiedergabe von Netzwerk-Unterbrechungen in einer Testumgebung für verteilte Systeme}


\author{Jonathan Arns
	\textit{Hochschule Mannheim} \\
	Fakultät für Informatik\\
	Paul-Wittsack-Str. 10\\
	68163 Mannheim\\
	jonathan.arns@stud.hs-mannheim.de
}

\maketitle

\tableofcontents

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Document beginning %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{abstract}
	Das ist das abstract, das werde ich wohl am Ende schreiben.
\end{abstract}


\chapter{Einleitung}

\chapter{Grundlagen}
\section{Verteilte Systeme}
\subsection{Partition Tolerance}
\subsection{CAP}
\subsection{Verteilter Consens}
\section{Docker}
Docker als leichtgewichtige Alternative zu virtuellen Maschinen ist inzwischen weitgehen bekannt und bildet das Rückrad vieler
moderner Cloud Anwendungen. Verteilte Microservice-basierte Systeme laufen heute fast ausschließlich in Containern und damit oft
in Docker oder ähnlichen Technologien.
\section{Proxy}

\chapter{State of the Art}
\cite{debugging_distributed_systems_2016}
\section{Tracing}
\section{Chaos Testing}
\cite{why_is_random_testing_effective}
\subsection{Jepsen}
\cite{abstracting_the_geniuses}

Jepsen ist ein Test Tool, welches speziell auf das Verhalten von verteilten Systemen bei Netwerk-Unterbrechungen u.Ä. ausgerichtet ist.
Jepsen hat sich auf dem Gebiet zu einem Industriestandart für das Testen von verteilte Datenbanken entwickelt und wird aktiv für Projekte wie
MongoDB, Couchbase, ScyllaDB, VoltDB, Hazelcast und CockroachDB verwendet und hat in jedem dieser Systeme bereits reale Bugs aufgedeckt.

Jepsen führt Tests aus, indem auf einem Kontrollknoten eine Reihe von Client Prozessen ausgeführt werden, die Requests an das verteilte System
senden. Gleichzeitig führt Jepsen mit Hilfe von sog. Nemesis Prozessen verschiedene Fehler in das System ein. Zur Erzeugung von
Netzwerk-Unterbrechungen verwenden die Nemesis Prozesse Linux Netwerk Tools wie iptables. Neben Netzwerk-Unterbrechungen ist Jepsen in
der Lage verschiedene andere Fehler zu erzeugen, wie beispielsweise Verzerrungen zwieschen den Systemuhren der einzelnen Knoten.

Jepsen ist im Kern eine Clojure Bibliothek, mit der Nutzer Tests schreiben können.


\chapter{Systembeschreibung}
Dieses Kapitel beschreibt die Idee, die Anforderungen und die Umsetzung des im Rahmen dieser Arbeit entwickelten Systems ditm.
\section{Idee}
Die grundlegende Idee dieser Arbeit ist ein Tool, welches nach Record and Replay Prinzip beim Debugging von Bugs im Zusammenhang
mit Netwerk-Unterbrechungen in verteilten Systemen helfen soll. Mit Hilfe eines solchen Tools sollen Netwerk-Unterbrechungen
während Test Durchläufen simuliert werden. Das Tool soll außerdem diese Test Durchläufe aufzeichnen und zum späteren Zeitpunkt
wieder abspielen können, insbesondere mit den gleichen Netzwerk-Bedingungen wie während der Aufzeichnung.

Der Kern der Arbeit ist dabei speziell der verfolgte Ansatz für ein solches System. Dieser ist, alle Nachrichten innerhalb eines
verteilten Systems über einen Proxy zu leiten, der diese inklusive Metadaten aufzeichnet und in der Lage ist, kontrolliert
Netwerk-Unterbrechungen zu simulieren, indem einzelne Nachrichten geblockt, bzw. nicht weiter geleitet, werden.
Mit diesem Aufbau soll dann auch ein Replay der Netzwerk-Bedingungen anhand eines zuvor durch den Proxy aufgezeichneten
Test Durchlaufs möglich sein, sofern der Proxy in der Lage ist, während des Replays für jeden erhaltenen Request zu identifizieren,
welchem Request aus der Aufzeichnung er jeweils zuzuordnen ist. Zudem muss der Proxy Requests, die in der Aufzeichnung von
außerhalb des Systems kamen, identifizieren und während des Replays zum richtigen Zeitpunkt selbstständig in das System senden.

\section{Anforderungen}
ditm ist ein Prototyp, der primär dem Zweck dient, die zuvor beschriebene Idee zu verfizieren.
Die Anforderung reflektieren diesem Umstand, indem beispielsweise die unterstützten Netwerk-Protokolle auf HTTP beschränkt sind.
\subsection{Funktionale Anforderungen}
\begin{table}[h]
	\begin{tabular}{|l|l|p{7cm}|}
		\hline
		ID   & Anforderung                   & Beschreibung                                                                                                                                                                                                          \\ \hline
		FA1  & Netzwerk Unterbrechungen      & Das System soll kontrolliert Netzwerk-Unterbrechungen zwischen Knoten des zu testenden Systems erzeugen können.                                                                                                       \\ \hline
		FA2  & Aufzeichnung                  & Das System soll den gesamten Netzwerkverkehr des zu testenden Systems aufzeichnen können. Insbesondere sollen auch erzeugte Netzwerk-Unterbrechungen aufgezeichnet werden.                                            \\ \hline
		FA3  & Replay                        & Das System soll anhand einer durch das System erstellten Aufzeichnung die Situation in der Aufzeichnung am laufenden Testsystem wiederherstellen und vor allem inklusive Netzwerk-Unterbrechungen wiedergeben können. \\ \hline
		FA4  & Zufällige Unterbrechungen     & Das System soll Netwerk-Unterbrechungen zufällig erzeugen können.                                                                                                                                                     \\ \hline
		FA5  & Kontrollierte Unterbrechungen & Das System soll dem Nutzer die Möglichkeit geben, Netwerk-Unterbrechungen konkret zu steuern.                                                                                                                         \\ \hline
		FA6  & Log Aggregation               & Das System soll zusätzlich zum Netzwerkverkehr auch die Log ausgaben des zu testenden Systems aufzeichnen und aggregieren können.                                                                                     \\ \hline
		FA7  & Log Matching                  & Das System soll die aufgezeichneten Nachrichten und Logs in chronologischer Reihenfolge gemeinsam anzeigen können.                                                                                                    \\ \hline
		FA8  & Volume Snapshots              & Das System soll für zustandsbehaftete Systeme Snapshots der Docker Volumes erstellen und zu einem späteren Zeitpunk wiederherstellen können.                                                                          \\ \hline
		FA9  & Nachrichten von außen         & Das System soll dem Nutzer Schnittstelle bieten, über die Nachrichten reproduzierbar von außen in das zu testende System gesendet werden können, um Prozesse im zu testenden System anzustoßen.                       \\ \hline
		FA10 & Responses Blocken             & Das System soll in der Lage sein, nicht nur Requests auf dem Hinweg zum Server zu blockieren, sondern optional auch erst die Antwort auf dem Rückweg.                                                                 \\ \hline
	\end{tabular}
\end{table}

\subsection{Nicht-Funktionale Anforderungen}
\begin{table}[h]
	\begin{tabular}{|l|l|p{7cm}|}
		\hline
		ID   & Anforderung              & Beschreibung                                                                                                                                                                                                  \\ \hline
		NFA1 & Portabilität             & Das System soll vollständig in Docker lauffähig sein und mittlels docker-compose konfigurierbar sein.                                                                                                         \\ \hline
		NFA2 & Proxy Architektur        & Umsetzung des Konzepts, einen Proxy zur erzeugung etc von Partitionen zu verwenden                                                                                                                            \\ \hline
		NFA3 & HTTP                     & Das System soll mit HTTP als Netzwerkprotokoll Arbeiten und grundlegend alle verteilten Systeme, die ausschließlich über HTTP kommunizieren und die Umgebungsvariable HTTP\_PROXY respektieren, unterstützen. \\ \hline
		NFA4 & Deterministische Replays & In der Wiedergabe einer Aufzeichnung sollen immer genau die Teile des Netzwerkverkehrs geblockt werden, die auch in der Aufzeichnung vom System geblockt wurden. Nicht mehr, nicht weniger und keine anderen. \\ \hline
		NFA5 & Usability                & Das System soll einfach über eine graphische Oberfläche bedienbar sein.                                                                                                                                       \\ \hline
		NFA6 & Echtzeit                 & Requests und Logs einer laufenden Aufzeichnung sollen in Echtzeicht angezeigt werden.                                                                                                                         \\ \hline
		NFA7 & Default Test System      & Das zu testenden System sollte für den Test nicht angepasst werden müssen.                                                                                                                                    \\ \hline
	\end{tabular}
\end{table}

\section{Architektur}
Das Herzstück des Systems ist entsprechend der Idee ein eigens entwickelter HTTP Proxy, welcher den Netzwerk-Verkehr in
einem verteilten System aufzeichnen und Nachrichten wahlweise nicht weiter leiten kann. Dieser Proxy läuft in einem
Docker Container direkt neben dem SUT und hängt auch im gleichen Docker Netzwerk wie das SUT. Neben dem Proxy hat
ditm eine weitere Komponente, ein Docker Log Driver Plugin, welches Container Logs an den Proxy sendet.
\subsection{Datenfluss}

\subsection{Datenmodell}
% Klassendiagramm
Das Datenmodell von ditm ist einfach gehalten. Das Top Level Datenobjekt ist das Recording, dieses enthält zwei chronologisch
geordnete Listen, eine mit den Log Nachrichten des SUT und eine mit den aufgezeichneten Requests. Beide Listen enthalten
die jeweiligen Objekte für alle Knoten des SUT, ohne diese weiter voneinander zu trennen. Sollte eine gefilterte Liste
benötigt werden, die nur Objekte für bestimmte Knoten enthält, wird diese dynamisch erzeugt. Recordings enthalten außerdem
eine Referenz auf einen Volume Snapshot, sofern für das Recording einer existiert.
Die eigentlichen Request Datenobjekte enthalten neben dem Request Body eine Menge Metadaten, die teilweise vom Request selbst
stammen und teilweise durch ditm erzeugt wurden, beispielsweise ob der Request geblockt wurde oder nicht.
Log Nachrichten umfassen neben der eigentlichen Nachricht ebenfalls wichtige Metadaten, wie den Namen des Containers, der die
Nachricht geloggt hat.
\subsection{Weg eines Requests}
% aktivitäts diagramm Abb. X
Um eine konkrete Vorstellung von der Arbeitsweise des Proxys zu vermitteln, wird im folgenden beispielhaft der Weg eines
Requests durch das System beschrieben. In diesem Kontext wird der Ursprung des Requests als Client und das Ziel des
Requests als Server bezeichnet, beide sind Knoten des SUT. Abb. X stellt zunächst den groben Ablauf auf Systemebene dar.
Wichtig ist zu bemerken, dass der Proxy bereits beim ersten erhalten des Requests die komplette Analyse durchführt und
nicht nur entscheidet, ob der Request geblockt werden soll, sondern die Entscheidung auch direkt für die Response trifft,
ohne die Response jemals gesehen zu haben. Tatsächlich wird die Response gar nicht von ditm betrachtet, stattdessen wird
die Analyse vollständig am Request durchgeführt. Die einzige Interaktion des Proxys mit der Response ist, diese zu blocken,
falls vorher festgelegt oder sie ansonsten direkt weiter zu leiten.
Der Grund dafür ist, dass fast alle für ditm relevanten Metadaten bereits aus dem Request abgeleitet werden können. Zwar
könnten die Länge der Response und die Response Header möglicherweise ebenfalls von Interesse sein, der Tradeoff wird
hier aber in Kauf genommen, da das die Implementierung erheblich vereinfacht und auch so genügend Metadaten vorliegen,
um verschiedene Ansätze zur Entscheidung, ob ein Reqeust im Replay geblockt werden soll, zu evaluieren.
Die verschiedenen Ansätze, die diese Arbeit betrachtet, werden in Kap. X Request Matcher behandelt.

\section{Implementierung}
Als Programmiersprache wird für die Implementierung auf Go gesetzt. Go bietet sich an, da die Standartbibliothek
sehr einfache, aber robuste APIs für den Umgang mit Netzwerken bietet und die Sprache insgesamt eine schnelle
Entwicklungsgeschwindigkeit erlaubt.
\subsection{Datenspeicherung}
Als Speicherformat für ditm wurden einfache Dateien in JSON Format gewählt. So wird jedes Recording Datenobjekt in
einer eigenen Datei serialisiert gespeichert. Dieses Format wurde einer Datenbank aus mehreren Gründen vorgezogen.
Zum einen wird Dateispeicher sowieso für die Volume Snapshots benötigt, die als Zip Dateien gespeichert werden,
es spart also an Komplexität für den Prototypen, für die restlichen Daten ein ähnliches Speichermodel zu wählen.
Zum anderen bieten Dateien den Vorteil, dass der Nutzer die Möglichkeit hat, diese selbst einzeln zu verwalten.
Es ist dem Nutzer also möglich, die Dateien einer einzelnen Aufzeichnung und des zugehörigen Snapshots getrennt
zu sichern oder einfach mit anderen Nutzern über einen generischen Filesharing Dienst zu teilen.
\subsection{Log Driver}
Um die Logging Ausgaben des SUT in ditm aggregieren zu können, muss ditm aus seinem Container heraus auf die Logs der
anderen Container zugreifen. Leider bietet Docker von sich aus keine einfache Möglichkeit dies zu konfigurieren,
stattdessen muss auf Dockers Plugin API zurück gegriffen werden. Immerhin bietet Docker eine spezielle Plugin API
für Log Driver, die es ermöglicht Log Nachrichten durch einen eigenen Driver beliebig weiter zu verarbeiten.
Für ditm wurde ein einfaches Log Driver Plugin entwickelt, welches Nachrichten als HTTP Request an eine beliebige URL
sendet. ditm selbst bietet in seiner API einen Endpunkt an, welcher diese Log Nachrichten empfangen und verarbeiten kann.
\subsection{Frontend}
Als Frontend bietet ditm dem Nutzer eine Web Oberfläche, in der laufende, sowie vergangene, Aufzeichnungen
tabellarisch visualisiert werden können. Des weiteren ist der Proxy vollständig über die GUI kontrollierbar.
Events einer laufenden Aufzeichnung werden in Echtzeicht per Server-Sent-Events Schnittstelle an das Frontend
gesendet und dort dargestellt.
Das Frontend selbst ist eine einfache, serverseitig gerenderte, HTML Seite mit dem notwendigen JavaScript Code,
um SSEs zu empfangen und zu verarbeiten. Die Seite ist mittels Bootstrap gestyled und in Tabs aufgeteilt.
\subsection{Request Matcher}
Die Logik zur Entscheidung, ob ein Request, bzw. eine Response, während eines Replays geblockt werden soll,
ist das Kernstück des Proxys, welches es ermöglicht, Aufzeichnungen zuverlässig wiederzugeben.
Das Problem lässt sich darauf herunterbrechen, genau den Request im ursprünglichen Recording zu identifizieren,
dem der aktuelle Request während des Replays entspricht. Das liegt daran, dass sich der Proxy während eines
Replays immer exact wie während der Aufnahme verhalten soll.

Der erste Schritt dabei, Requests aus Recording und Replay zu matchen, ist immer die Requests sowohl im
Recording als auch im Replay nach dem StreamIdentifier des aktuellen Requests zu filtern, so dass zwei
kleinere Request Streams entstehen. Der StreamIdentifier wird zusammengesetzt aus den Namen des Clients
und des Servers für den jeweiligen Request, ein so gefilterter Stream stellt also den gesamten Verkehr
zwischen genau zwei Knoten des SUT dar.
Der Rest des Matchings ist über ein Single-Method-Interface abstrahiert, um leicht mehrere Implementierungen
austauschen zu können. Die Methode Match des Interfaces erwartet als Parameter den aktuellen Request,
dessen Index im gefilterten Stream des Replays und den gesamten gefilterten Stream des Recordings.
Insgesamt wurden X Implementierungen für das Interface mit verschiedenen Algorithmen erstellt, die im Folgenden
dargestellt und später gegeneinander evaluiert werden.
\subsubsection{Zählend}
\subsubsection{Exact}
\subsubsection{Heutistisch}
\subsubsection{Mix}

\section{Nutzung}
\subsection{Konfiguration}
\subsection{Bedienung}

\chapter{Evaluation}
In diesem Kapitel werden anhand des beschriebenen Prototypen die folgenden Hypothesen untersucht:
- Wie gut funktionieren Replays von Netwerk-Unterbrechungen über einen Proxy?
- Wie gut funktioniert die chronologische Ordnung von Log Nachrichten relativ zu Requests?
- Kann der verfolgte Ansatz hilfreich für einen menschlichen Debugging Prozess sein?
\section{Synthetisch}
Ziel dieses Szenarios ist es, die Grenzen von ditm im Bezug auf die ersten beiden Fragen auszuloten.
Dazu wird eine große Menge an eindeutig identifizierbarer Requests unter leicht unterschiedlichen Bedingungen gesendet.
Da sich ditm beim Log-Matching auf Zeitstempel verlässt und diese für die Logs von Docker kommen, ist die Erwartung,
dass das Log-Matching in allen Situationen akzeptabel funktioniert. Für das Reqeust Matching ist die Erwartungshaltung, dass
der ...Mix Matcher am besten funktioniert, dicht gefolgt vom ... heuristic Matcher.
\subsection{Versuchsaufbau}
Das Test System ist ein einfacher HTTP Server mit zwei Endpunkten. Einer davon löst
eine große Menge an Requests aus, der andere verarbeitet diese. Es wird für den Versuch ein Cluster aus zwei identischen
Knoten verwendet, wovon einer die Rolle eines API Gateways einnimmt, über das von außen der Versuch ausgelöst wird,
und der andere die eines dahinter verborgenen Services. Da ditm den Request-Fluss zwischen zwei Knoten des SUT immer einzeln
betrachtet, genügen zwei Knoten aus, um die Grenzen des Request-Matchings abzustecken.
Die Requests, die der Gateway Knoten versendet, sind anhand eines Query Parameters eindeutig identifizierbar.
Der Endpunkt versendet die Requests in einer Schleife und bietet neben der Anzahl zu versendener Reqeusts verschiedene
andere Konfigurationsmöglichkeiten, um den Strom von Requests zu verändern.
Die Requests können in vollständig fester oder in unterschiedlich stark gemischter Reihenfolge erfolgen. Dabei ist konfigurierbar,
wie weit jeder Request maximal von seiner eigentlichen Position im Fluss entfernt sein darf. Eine maximale Entfernung
von 0 entspricht immer einem vollständig geordneten Fluss, für jeden anderen Wert wird der Fluss für jede Ausführung neu
zufällig gemischt, so dass ditm die Requests während eines Replays also in anderer Reihenfolge erhält, als während der
Aufzeichnung. In folgendem Beispiel sind mögliche Anordnungen von Requests dargestellt, in Klammern steht jeweils die
entsprechende maximale Entfernung.
\begin{verbatim}
(0): 0 1 2 3 4 5 6 7 8 9
(1): 1 0 2 4 3 6 5 7 9 8
(2): 0 3 2 1 5 6 4 9 7 8
(3): 4 2 1 0 7 3 9 5 6 8
\end{verbatim}
Requests können außerdem optional asynchron erfolgen, was ebenfalls dazu führt dass sie in stark gemischter Reihenfolge und nahezu gleichzeitig
gesendet werden.
Zusätzlich besteht Möglichkeit, entweder einfache GET Requests zu senden, die selben GET Requests mit einem Zeitstempel
als zusätzlichem Parameter oder POST Requests mit einem Zeitstempel und einem zusätzlichen Füller im Body. Der Füller hat eine von
drei Längen, somit dient der Request-Body als weiteres Merkmal für ditm, um Requests identifizierbar zu machen. Die Zeitstempel dienen
genau genau umgekehrt dazu, Reqeusts schwieriger identifizierbar zu machen, indem ditm durch die Zeitstempel die Query Parameter,
bzw. die Bodies der Requests nicht mehr einfach direkt miteinander vergleichen kann, um Reqeusts zu identifizieren.
Zu letzt gibt es die Möglichkeit, für den verwendeten HTTP Client (Go net/http) die Wiederverwendung von TCP Verbingungen mit Keep-Alive
zu deaktivieren. Dies ist notwendig, da der Client sonst in bestimmten Situationen Retries sendet, was durch diese Einstellung
verhindert werden kann.

Für die Evaluation werden einfache GET Requests, GET Requests mit Zeitstempel, GET Reqeusts ohne Keep-Alive, GET Requests mit
Zeitstempel und ohne Keep-Alive und POST Requests verwendet. Für jede Art von Reqeust werden Experimente mit fünf unterschiedlichen
Konfigurationen zur Reihenfolge der Requests durchgeführt. Diese sind asynchron, synchron mit fester Reihenfolge und synchron mit gemischter
Reihenfolge mit maximalen Entfernungen von 1, 2 und 3. Zusätzlich wird jedes Experiment einmal mit 10 Requests und einmal mit 100 Requests
durchgeführt.

In jedem Experiment werden 10 voneinander unabhängige Aufzeichnungen erstellt. Von jeder Aufzeichnung wird dann mit jedem der vier
Request-Matcher ein Replay durchgeführt. Für jedes Replay wird anhand von dazu bestimmten Log Ausgaben des Test Systems bestimmt,
wie viele Requests ditm falsch behandelt hat. Aus diesem Wert wird dann pro Request-Matcher über die 10 erzeugten Replays der Durchschnitt
und der Median der falsch behandelten Requests berechnet. Diese Werte bilden das Ergebnis des jeweiligen Experiments.
Alle Experimente zum Request-Matching werden vollständig automatisiert durchgeführt und ausgewertet. % (Das Python Script hierfür ist im Repo)

Da die chronologische Darstellung von Logs zwischen den Requests leider nicht so leicht automatisch auswertbar ist, werden hierfür
zusätzliche Experimente von Hand durchgeführt und ausgewertet. Es werden insgesamt vier Experimente durchgeführt, bei denen eine
Aufzeichnung mit jeweils 10 und 100 Requests einmal synchron und einmal asynchron erstellt wird. Das Ergebnis hierbei ist jeweils
die maximale Entfernung einer Log Nachricht von ihrer korrekten Position und die Gesamtzahl an Nachrichten, die an falscher Stelle
eingeordnet wurden. Da das Matching der Request- und Log-Flüsse im Replay exact gleich funktioniert, wie in der Aufzeichnung, sind
für die Evaluation des Log-Matchings keine Replays notwendig.

\subsection{Ein Bug im SUT}
Ziel dieser Experimente ist ganz klar, mit einem sehr kontrollierten SUT die Grenzen von ditm auf technischer Ebene zu finden.
Schon bei der ersten händischen Durchführung der ersten Experimente viel allerdings auf, dass dabei etwas nicht stimmen konnte.
Nicht nur waren die Ergebnisse niederschmetternd, nach genauerem hinsehen fanden sich in den Aufzeichnungen auch teilweise deutlich
mehr Requests als für das jeweilige Experiment vorgesehen. Nachdem ditms Proxy selbst als Quelle dieser zusätzlichen Requests
in einer langen Debugging Session nahezu sicher ausgeschlossen werden konnte, war klar: Es muss einen Bug im SUT geben.

ditm erwies sich in diesem Fall als excellent geeignetes Debugging Werkzeug.

\subsection{Ergebnisse}
\begin{table}[h]
	\begin{tabular}{|l|l|l|l|l|}
		\hline
		Anzahl Requests & Anzahl Logs & async & maximaler Fehler & Anzahl Fehler \\ \hline
		10              & 18          & nein  & 1                & 1             \\ \hline
		100             & 178         & nein  & 1                & 8             \\ \hline
		10              & 19          & ja    & 15               & 17            \\ \hline
		100             & 165         & ja    & 121              & 162           \\ \hline
	\end{tabular}
\end{table}
Es ist Anzumerken, dass die Anzahl der Fehler und auch der maximale Fehler bei den asynchronen Experimenten Schätzwerte sind, da durch
die asynchrone Natur der Experimente bei manchen Logs nicht eindeutig zu sagen ist, ob sie an richtiger Stelle stehen oder nicht.
Trotzdem sollten die Werte ausreichen, um zu demonstrieren, dass das Log-Matching bei hoch asynchronen Prozessen mit vielen schnellen Logs
und Reqeusts an seine Grenzen kommen kann und dann effektiv unbrauchbar wird.

Eine weitere interessante Beobachtung ist, dass in dem längeren der beiden synchronen Experimenten die Fehler vorwiegend eng zusammen in Clustern
von zwei bis drei Fehlern direkt hintereinander auftreten. Bei den asynchronen Experimenten stehen die fast alle Requests gemischt mit nur
sehr wenigen Logs am Anfang der Aufzeichnung und fast alle Logs kommen am Ende der Aufzeichnung hinter allen Reqeusts. Beides deutet darauf hin,
dass nicht der ditm Proxy selbst, welcher die Logs sammelt, den Flaschenhals bildet, sondern bereits der Docker Daemon selbst oder wahrscheinlicher
der verwendete HTTP-Log-Driver, da die Zeitstempel, welche zur Sortierung der Tabelle von Reqeusts und Logs verwendet werden, in diesem Teil des
Systems generiert werden.

\begin{table}[h]
	\centering
	\caption{get}
	\label{tab:get}
	\begin{tabular}{|l|l|l|l|l|l|l|l|l|l|l|l|}
		\hline
		\multirow{2}{*}{Shuffle} & \multicolumn{2}{|c|}{num requests} & \multicolumn{2}{|c|}{heuristic} & \multicolumn{2}{|c|}{exact} & \multicolumn{2}{|c|}{mix} & \multicolumn{2}{|c|}{counting}                                          \\ \cline{2-11}
		                         & avg                                & median                          & avg                         & median                    & avg                            & median & avg  & median & avg  & median \\ \hline
		no                       & 13.3                               & 13.5                            & 0.8                         & 0.0                       & 0.8                            & 0.0    & 0.8  & 0.0    & 1.7  & 0.0    \\ \hline
		no                       & 133.6                              & 133.0                           & 2.9                         & 0.0                       & 0.3                            & 0.0    & 2.9  & 0.0    & 15.2 & 0.0    \\ \hline
		1                        & 13                                 & 13.0                            & 1.7                         & 1.5                       & 2.2                            & 2.0    & 1.7  & 2.0    & 2.6  & 2.5    \\ \hline
		1                        & 133.2                              & 134.0                           & 22.7                        & 23.0                      & 39.1                           & 38.0   & 23.6 & 25.0   & 34.6 & 36.5   \\ \hline
		2                        & 13.5                               & 14.0                            & 2.5                         & 2.5                       & 3.0                            & 3.0    & 2.5  & 3.0    & 3.3  & 4.0    \\ \hline
		2                        & 131.5                              & 130.0                           & 22.5                        & 21.5                      & 40.3                           & 42.5   & 21.4 & 20.0   & 45.2 & 46.0   \\ \hline
		3                        & 13.3                               & 14.0                            & 2.0                         & 2.0                       & 3.5                            & 3.0    & 2.3  & 2.5    & 4.5  & 4.0    \\ \hline
		3                        & 135.1                              & 137.0                           & 25.8                        & 27.0                      & 42.2                           & 39.0   & 24.8 & 27.5   & 46.7 & 47.0   \\ \hline
		async                    & 13                                 & 14.0                            & 1.5                         & 1.5                       & 3.4                            & 4.0    & 1.4  & 1.0    & 5.5  & 5.0    \\ \hline
		async                    & 113.1                              & 111.5                           & 7.2                         & 6.5                       & 30.7                           & 31.0   & 7.0  & 6.0    & 68.2 & 67.0   \\ \hline
	\end{tabular}
\end{table}

\begin{table}[h]
	\centering
	\caption{get + timestamp}
	\label{tab:get}
	\begin{tabular}{|l|l|l|l|l|l|l|l|l|l|l|l|}
		\hline
		\multirow{2}{*}{Shuffle} & \multicolumn{2}{|c|}{num requests} & \multicolumn{2}{|c|}{heuristic} & \multicolumn{2}{|c|}{exact} & \multicolumn{2}{|c|}{mix} & \multicolumn{2}{|c|}{counting}                                          \\ \cline{2-11}
		                         & avg                                & median                          & avg                         & median                    & avg                            & median & avg  & median & avg  & median \\ \hline
		no                       & 13.6                               & 14.0                            & 0.7                         & 0.0                       & 0.9                            & 0.0    & 1.2  & 0.0    & 2.1  & 0.0    \\ \hline
		no                       & 134.7                              & 136.5                           & 19.6                        & 0.0                       & 19.0                           & 0.0    & 9.4  & 0.0    & 19.9 & 0.0    \\ \hline
		1                        & 13.8                               & 14.0                            & 3.3                         & 3.0                       & 3.0                            & 2.5    & 3.8  & 4.0    & 3.0  & 3.5    \\ \hline
		1                        & 135.4                              & 137.5                           & 37.0                        & 37.0                      & 36.2                           & 35.0   & 36.7 & 36.5   & 38.1 & 39.5   \\ \hline
		2                        & 13.4                               & 13.0                            & 3.7                         & 4.0                       & 4.3                            & 4.5    & 3.2  & 3.5    & 3.4  & 3.0    \\ \hline
		2                        & 134.1                              & 133.5                           & 42.0                        & 41.0                      & 43.1                           & 45.0   & 40.0 & 37.5   & 42.9 & 42.0   \\ \hline
		3                        & 13.2                               & 13.0                            & 4.1                         & 4.0                       & 5.3                            & 6.0    & 5.0  & 6.0    & 4.8  & 5.0    \\ \hline
		3                        & 134.5                              & 134.5                           & 48.8                        & 47.0                      & 48.3                           & 47.5   & 50.8 & 51.5   & 49.1 & 48.0   \\ \hline
		async                    & 13.7                               & 13.5                            & 5.0                         & 5.0                       & 5.6                            & 5.0    & 6.1  & 6.0    & 6.2  & 6.5    \\ \hline
		async                    & 113.4                              & 108.0                           & 60.9                        & 60.0                      & 65.2                           & 65.0   & 65.0 & 65.0   & 65.6 & 66.5   \\ \hline
	\end{tabular}
\end{table}

\begin{table}[h]
	\centering
	\caption{get + no keep alive}
	\label{tab:get}
	\begin{tabular}{|l|l|l|l|l|l|l|l|l|l|l|l|}
		\hline
		\multirow{2}{*}{Shuffle} & \multicolumn{2}{|c|}{num requests} & \multicolumn{2}{|c|}{heuristic} & \multicolumn{2}{|c|}{exact} & \multicolumn{2}{|c|}{mix} & \multicolumn{2}{|c|}{counting}                                         \\ \cline{2-11}
		                         & avg                                & median                          & avg                         & median                    & avg                            & median & avg & median & avg  & median \\ \hline
		no                       & 10                                 & 10.0                            & 0.0                         & 0.0                       & 0.0                            & 0.0    & 0.0 & 0.0    & 0.0  & 0.0    \\ \hline
		no                       & 100                                & 100.0                           & 0.0                         & 0.0                       & 0.0                            & 0.0    & 0.0 & 0.0    & 0.0  & 0.0    \\ \hline
		1                        & 10                                 & 10.0                            & 0.0                         & 0.0                       & 1.7                            & 2.0    & 0.0 & 0.0    & 4.2  & 3.5    \\ \hline
		1                        & 100                                & 100.0                           & 0.0                         & 0.0                       & 22.5                           & 22.5   & 0.0 & 0.0    & 40.2 & 41.0   \\ \hline
		2                        & 10                                 & 10.0                            & 0.0                         & 0.0                       & 2.5                            & 2.0    & 0.0 & 0.0    & 3.6  & 4.0    \\ \hline
		2                        & 100                                & 100.0                           & 0.0                         & 0.0                       & 25.4                           & 25.5   & 0.0 & 0.0    & 48.8 & 50.5   \\ \hline
		3                        & 10                                 & 10.0                            & 0.0                         & 0.0                       & 2.2                            & 2.0    & 0.0 & 0.0    & 5.0  & 5.0    \\ \hline
		3                        & 100                                & 100.0                           & 0.0                         & 0.0                       & 25.4                           & 25.0   & 0.0 & 0.0    & 52.2 & 53.0   \\ \hline
		async                    & 10                                 & 10.0                            & 0.0                         & 0.0                       & 2.5                            & 2.5    & 0.0 & 0.0    & 7.3  & 7.5    \\ \hline
		async                    & 100                                & 100.0                           & 0.0                         & 0.0                       & 22.4                           & 21.5   & 0.0 & 0.0    & 68.2 & 65.5   \\ \hline
	\end{tabular}
\end{table}

\begin{table}[h]
	\centering
	\caption{get + timestamp + no keep alive}
	\label{tab:get}
	\begin{tabular}{|l|l|l|l|l|l|l|l|l|l|l|l|}
		\hline
		\multirow{2}{*}{Shuffle} & \multicolumn{2}{|c|}{num requests} & \multicolumn{2}{|c|}{heuristic} & \multicolumn{2}{|c|}{exact} & \multicolumn{2}{|c|}{mix} & \multicolumn{2}{|c|}{counting}                                          \\ \cline{2-11}
		                         & avg                                & median                          & avg                         & median                    & avg                            & median & avg  & median & avg  & median \\ \hline
		no                       & 10                                 & 10.0                            & 0.0                         & 0.0                       & 0.0                            & 0.0    & 0.0  & 0.0    & 0.0  & 0.0    \\ \hline
		no                       & 100                                & 100.0                           & 0.0                         & 0.0                       & 0.0                            & 0.0    & 0.0  & 0.0    & 0.0  & 0.0    \\ \hline
		1                        & 10                                 & 10.0                            & 3.4                         & 3.0                       & 4.3                            & 4.0    & 3.7  & 4.0    & 3.5  & 3.5    \\ \hline
		1                        & 100                                & 100.0                           & 40.7                        & 39.0                      & 43.8                           & 45.0   & 40.4 & 40.0   & 43.7 & 43.0   \\ \hline
		2                        & 10                                 & 10.0                            & 5.3                         & 5.5                       & 4.9                            & 5.0    & 5.0  & 4.5    & 4.4  & 4.0    \\ \hline
		2                        & 100                                & 100.0                           & 50.6                        & 51.5                      & 48.7                           & 48.0   & 50.9 & 52.5   & 48.4 & 48.0   \\ \hline
		3                        & 10                                 & 10.0                            & 4.6                         & 5.0                       & 4.3                            & 4.0    & 4.5  & 4.5    & 5.7  & 6.0    \\ \hline
		3                        & 100                                & 100.0                           & 48.5                        & 50.0                      & 50.8                           & 51.0   & 49.9 & 50.0   & 50.4 & 48.5   \\ \hline
		async                    & 10                                 & 10.0                            & 5.0                         & 5.0                       & 5.7                            & 6.0    & 4.9  & 4.5    & 7.7  & 7.5    \\ \hline
		async                    & 100                                & 100.0                           & 61.5                        & 60.5                      & 60.0                           & 61.0   & 62.4 & 62.5   & 68.7 & 69.0   \\ \hline
	\end{tabular}
\end{table}

\begin{table}[h]
	\centering
	\caption{post}
	\label{tab:get}
	\begin{tabular}{|l|l|l|l|l|l|l|l|l|l|l|l|}
		\hline
		\multirow{2}{*}{Shuffle} & \multicolumn{2}{|c|}{num requests} & \multicolumn{2}{|c|}{heuristic} & \multicolumn{2}{|c|}{exact} & \multicolumn{2}{|c|}{mix} & \multicolumn{2}{|c|}{counting}                                          \\ \cline{2-11}
		                         & avg                                & median                          & avg                         & median                    & avg                            & median & avg  & median & avg  & median \\ \hline
		no                       & 10                                 & 10.0                            & 0.0                         & 0.0                       & 0.0                            & 0.0    & 0.0  & 0.0    & 0.0  & 0.0    \\ \hline
		no                       & 100                                & 100.0                           & 0.0                         & 0.0                       & 0.0                            & 0.0    & 0.0  & 0.0    & 0.0  & 0.0    \\ \hline
		1                        & 10                                 & 10.0                            & 0.7                         & 1.0                       & 3.1                            & 2.5    & 0.8  & 1.0    & 4.0  & 4.0    \\ \hline
		1                        & 100                                & 100.0                           & 8.0                         & 8.5                       & 42.0                           & 41.0   & 7.3  & 6.5    & 46.4 & 45.5   \\ \hline
		2                        & 10                                 & 10.0                            & 1.3                         & 1.0                       & 3.8                            & 3.5    & 1.5  & 1.0    & 3.9  & 4.0    \\ \hline
		2                        & 100                                & 100.0                           & 23.6                        & 22.5                      & 44.5                           & 44.5   & 24.9 & 25.0   & 46.6 & 46.5   \\ \hline
		3                        & 10                                 & 10.0                            & 2.3                         & 2.0                       & 4.4                            & 5.0    & 3.2  & 3.0    & 4.3  & 5.0    \\ \hline
		3                        & 100                                & 100.0                           & 31.2                        & 31.5                      & 46.6                           & 45.5   & 27.4 & 25.5   & 50.2 & 49.5   \\ \hline
		async                    & 10                                 & 10.0                            & 5.1                         & 5.0                       & 5.4                            & 6.0    & 4.4  & 4.5    & 7.0  & 7.0    \\ \hline
		async                    & 100                                & 100.0                           & 59.6                        & 59.0                      & 58.9                           & 60.0   & 58.6 & 58.5   & 66.7 & 67.5   \\ \hline
	\end{tabular}
\end{table}


\section{Konstostand}
\subsection{Versuchsaufbau}
\subsection{Ergebnisse}
\section{Raft}
\subsection{Versuchsaufbau}
\subsection{Ergebnisse}
\section{Microservices}
\subsection{Versuchsaufbau}
\subsection{Ergebnisse}

\chapter{Ergebnis}

\chapter{Future Work}

\chapter{Fazit}

\printbibliography

\end{document}
